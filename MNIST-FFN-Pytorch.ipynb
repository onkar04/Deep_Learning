{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f02da80b362a4233b75cb0f9e9656525e37befa",
    "colab_type": "text",
    "id": "L45gM0dy4C9z"
   },
   "source": [
    "![](images/mlp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "4e83a9e422c10eb07cbfb779be01803d2b8a5334",
    "colab": {},
    "colab_type": "code",
    "id": "DtAM0yxR4DCl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/train.csv\n",
      "/kaggle/input/sample_submission.csv\n",
      "/kaggle/input/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset ,DataLoader\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "661e23266c2c882d34cdae4c9074d26c0d2ac040",
    "colab_type": "text",
    "id": "Gj48dSJg4DCm"
   },
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "72b61aac15c29fc295d77130b07d1110c9cb1825",
    "colab": {},
    "colab_type": "code",
    "id": "mdn255g54DCm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('/kaggle/input/train.csv')\n",
    "test=pd.read_csv('/kaggle/input/test.csv')\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d5eb02dbfc5e385ffd113560494e0b2275e5f66",
    "colab_type": "text",
    "id": "Hf9bGVDH4DCn"
   },
   "source": [
    "## Extracting Input and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "858a074c0e1dea92562d0f1bd93ff5302f861643",
    "colab": {},
    "colab_type": "code",
    "id": "XF2vEl_t4DCo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=train.drop(\"label\",axis=1)\n",
    "y=np.array(train['label'])\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "454f4fb8e0a416e60aed471a49850c01a64a77e6",
    "colab_type": "text",
    "id": "0ZOWCRtq4DCw"
   },
   "source": [
    "## Train -Test Split -Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d616496f4e453322efe8aecfa71b17fcdddaa8dd",
    "colab": {},
    "colab_type": "code",
    "id": "ni3rH-Pi4DCw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of trainSet 33600 , len of testSet 8400\n"
     ]
    }
   ],
   "source": [
    "torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255\n",
    "torch_y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
    "myDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "valid_no  = int(0.2 * len(myDataset))\n",
    "# so divide the data into trainset and testset\n",
    "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
    "print(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\n",
    "batch_size=64\n",
    "train_loader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \n",
    "test_loader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97b2925a24f59b10a16864a76f00e02a4c92b36f",
    "colab_type": "text",
    "id": "_hGrdIVq4DCy"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "8cbe1c508bacadbb875014318a35fed17ab6a3a1",
    "colab": {},
    "colab_type": "code",
    "id": "nW1wypfS4DCy"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=0.04, weight_decay= 1e-7, momentum = 0.9, nesterov = True)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2bea512cd5bd9f4f41bd77044f471e644505a5fa",
    "colab_type": "text",
    "id": "wr91w0-X4DCz"
   },
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "2df4882ed86f9b17b4bba52d56adfde46d1f718d",
    "colab": {},
    "colab_type": "code",
    "id": "9x_1PS6x4DC0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25..  Training Loss: 0.589..  Test Loss: 0.176..  Test Accuracy: 0.948\n",
      "Epoch: 2/25..  Training Loss: 0.201..  Test Loss: 0.144..  Test Accuracy: 0.958\n",
      "Epoch: 3/25..  Training Loss: 0.153..  Test Loss: 0.104..  Test Accuracy: 0.971\n",
      "Epoch: 4/25..  Training Loss: 0.129..  Test Loss: 0.104..  Test Accuracy: 0.970\n",
      "Epoch: 5/25..  Training Loss: 0.106..  Test Loss: 0.095..  Test Accuracy: 0.974\n",
      "Epoch: 6/25..  Training Loss: 0.093..  Test Loss: 0.093..  Test Accuracy: 0.973\n",
      "Epoch: 7/25..  Training Loss: 0.084..  Test Loss: 0.099..  Test Accuracy: 0.973\n",
      "Epoch: 8/25..  Training Loss: 0.075..  Test Loss: 0.087..  Test Accuracy: 0.977\n",
      "Epoch: 9/25..  Training Loss: 0.067..  Test Loss: 0.079..  Test Accuracy: 0.978\n",
      "Epoch: 10/25..  Training Loss: 0.062..  Test Loss: 0.086..  Test Accuracy: 0.978\n",
      "Epoch: 11/25..  Training Loss: 0.057..  Test Loss: 0.088..  Test Accuracy: 0.979\n",
      "Epoch: 12/25..  Training Loss: 0.053..  Test Loss: 0.079..  Test Accuracy: 0.980\n",
      "Epoch: 13/25..  Training Loss: 0.049..  Test Loss: 0.088..  Test Accuracy: 0.978\n",
      "Epoch: 14/25..  Training Loss: 0.043..  Test Loss: 0.104..  Test Accuracy: 0.975\n",
      "Epoch: 15/25..  Training Loss: 0.043..  Test Loss: 0.095..  Test Accuracy: 0.979\n",
      "Epoch: 16/25..  Training Loss: 0.044..  Test Loss: 0.083..  Test Accuracy: 0.979\n",
      "Epoch: 17/25..  Training Loss: 0.036..  Test Loss: 0.086..  Test Accuracy: 0.980\n",
      "Epoch: 18/25..  Training Loss: 0.037..  Test Loss: 0.094..  Test Accuracy: 0.978\n",
      "Epoch: 19/25..  Training Loss: 0.030..  Test Loss: 0.087..  Test Accuracy: 0.981\n",
      "Epoch: 20/25..  Training Loss: 0.033..  Test Loss: 0.096..  Test Accuracy: 0.978\n",
      "Epoch: 21/25..  Training Loss: 0.033..  Test Loss: 0.093..  Test Accuracy: 0.979\n",
      "Epoch: 22/25..  Training Loss: 0.031..  Test Loss: 0.090..  Test Accuracy: 0.981\n",
      "Epoch: 23/25..  Training Loss: 0.031..  Test Loss: 0.088..  Test Accuracy: 0.978\n",
      "Epoch: 24/25..  Training Loss: 0.028..  Test Loss: 0.085..  Test Accuracy: 0.981\n",
      "Epoch: 25/25..  Training Loss: 0.025..  Test Loss: 0.098..  Test Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "epochs=25\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9373aea13cc5891684fb8b801cbcd0ac17eff458",
    "colab_type": "text",
    "id": "_vC0Y7z34DC1"
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bfcc3f17cadca0bf48cec130586b907965905ed6",
    "colab": {},
    "colab_type": "code",
    "id": "5gmUDHdA4DC2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f83335753469344d38ac362053a74fad30b0ca3e",
    "colab": {},
    "colab_type": "code",
    "id": "5xfl0hTJ4DC3"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "abd854b1c8bfed532cb4e64578c40fd29dea9a36",
    "colab": {},
    "colab_type": "code",
    "id": "nnS5Suqe4DC4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7a889737952161eb1834f521476f0f1c8448570a",
    "colab": {},
    "colab_type": "code",
    "id": "0iHEd3Nk4DC6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "a08eff1adeb3a8f8f7a31356828ee732a557c3d5",
    "colab": {},
    "colab_type": "code",
    "id": "EOVzZilI4DC7"
   },
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [256,128,64],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3356c9580d6c01685a52a11f906ee1c9dbe7ef1",
    "colab_type": "text",
    "id": "B-j6vcfk4DC9"
   },
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "34abb15aa48ad4f133ee15a2f9a5268b45692c36",
    "colab": {},
    "colab_type": "code",
    "id": "8oA5JqIJ4DC9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28000, 784])\n"
     ]
    }
   ],
   "source": [
    "test_images = pd.read_csv(\"/kaggle/input/test.csv\")\n",
    "test_image = test_images.loc[:,test_images.columns != \"label\"].values\n",
    "test_dataset = torch.from_numpy(test_image).type(torch.FloatTensor)/255\n",
    "print(test_dataset.shape)\n",
    "#test_dataset = torch.utils.data.TensorDataset(test_dataset)\n",
    "new_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "790dd7f94c59a6de5441827b999b6cff6f686154",
    "colab": {},
    "colab_type": "code",
    "id": "dwpwU0h04DC-"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images in new_test_loader:\n",
    "        output = model(images)\n",
    "        ps = torch.exp(output)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        results += top_class.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f9b334b1c25c4bb1a48fda6b64634f1f90b7565",
    "colab_type": "text",
    "id": "4ZwCEHs24DC_"
   },
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "56ffd3051274596232af3ca4d1a9ee7d6322881a",
    "colab": {},
    "colab_type": "code",
    "id": "iJ2mowPf4DDA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 9 3]\n",
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(results).flatten()\n",
    "print(predictions[:5])\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f946013a3eab6274d1becd93dfe99aa9f7491cf9",
    "colab_type": "text",
    "id": "dMLPVy7c4DDB"
   },
   "source": [
    "## Submit for Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "655160a6e2d490651c0fe70b8ba7480ed8ba1fcc",
    "colab": {},
    "colab_type": "code",
    "id": "xFG3HrNH4DDC"
   },
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"my_submissions.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Phase - 1_Session-1 and 2_DL_with_Pytorch_MNIST_Classification_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
